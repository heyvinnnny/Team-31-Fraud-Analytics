{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "random_state = 4012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Processed Data Files/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../Processed Data Files/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    }
   ],
   "source": [
    "# Combine them!\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot = OneHotEncoder(\n",
    "    categories = [\n",
    "            ['full time', 'contract', 'part time','flexi','other','unspecified'], # employment_type\n",
    "            ['entry level', 'middle level', 'senior level', 'unspecified'], # required_experience\n",
    "            ['high school or vocational degree', 'undergraduate', 'graduate', 'unspecified'], # required_education\n",
    "    ],\n",
    "    handle_unknown = 'ignore',  # <- Ignore unknown values (i.e. don't create a column for them)\n",
    ")\n",
    "\n",
    "freq_encoder = CountEncoder()\n",
    "\n",
    "binary_columns = ['telecommuting', 'has_company_logo','has_questions', 'have_company_profile', 'have_requirements', 'have_benefits', 'have_category', 'high_salary']\n",
    "numerical_columns = ['flesch_score_bin_ft','fk_grade_level_bin_ft', 'text_len']\n",
    "onehot_columns = ['employment_type', 'required_experience','required_education']\n",
    "freq_columns = ['location_country']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    # (nickname, transformer to apply, columns to apply to)\n",
    "    ('binary', 'passthrough', binary_columns),  # <- 'passthrough' says to keep them but don't apply anything\n",
    "    ('numerical', scaler, numerical_columns),   \n",
    "    ('onehot', onehot, onehot_columns),\n",
    "    ('frequency',freq_encoder, freq_columns),\n",
    "],  remainder='passthrough')\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    # ('resampling', SMOTEENN(random_state=random_state,enn=EditedNearestNeighbours(sampling_strategy='majority'))),\n",
    "    ('train', RandomForestClassifier(random_state=random_state,class_weight='balanced')),\n",
    "])\n",
    "\n",
    "params = dict(\n",
    "    train__n_estimators = [10, 50, 100],\n",
    "    train__criterion = [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    train__min_samples_leaf = [5, 10, 20],\n",
    "    train__max_depth = [5, 6, 7, 8, 9],\n",
    "    train__max_features = [\"sqrt\",\"log2\"]\n",
    ")\n",
    "\n",
    "def train(x_train,y_train,model,params):\n",
    "    gridsearchcv = GridSearchCV(model, params, cv=5, scoring='f1_weighted', verbose=3, n_jobs=-1)\n",
    "    gridsearchcv.fit(x_train, y_train.values)\n",
    "    best_model = model.set_params(**gridsearchcv.best_params_).fit(x_train, y_train.values)\n",
    "    return best_model\n",
    "\n",
    "# train\n",
    "# start = time.time()\n",
    "best_model = train(X_train,y_train,model,params)\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/random_forest.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"../Models/\" # path where the file is going to be saved in \n",
    "\n",
    "model_name = 'random_forest'\n",
    "\n",
    "model_path = os.path.join(base_path, f'{model_name}.joblib')\n",
    "\n",
    "joblib.dump(best_model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
